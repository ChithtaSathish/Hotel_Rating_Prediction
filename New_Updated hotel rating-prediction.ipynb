{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries for data manipulation and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "# text/file processing libraries\n",
    "import string\n",
    "import re\n",
    "import sys\n",
    "from nltk.corpus import stopwords\n",
    "from itertools import chain\n",
    "# warnings\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM,GRU\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten,Activation, Dropout\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>exceptional service nice all-around daughter s...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>beautiful relaxing jw marriott desert ridge re...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>great location great location 5 mins subway ta...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>pleased nice safe hotel, flower market hotel v...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>excellent hotel service great hotel excellent ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14338</th>\n",
       "      <td>14338</td>\n",
       "      <td>hotel madrid hotel perfect, location tiny quie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14339</th>\n",
       "      <td>14339</td>\n",
       "      <td>excellent hotel stay florence hotel chosen tri...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14340</th>\n",
       "      <td>14340</td>\n",
       "      <td>great place relax know looking vacation book t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14341</th>\n",
       "      <td>14341</td>\n",
       "      <td>better just got week seattle loved minute, pac...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14342</th>\n",
       "      <td>14342</td>\n",
       "      <td>stay clear, internet reservation friday rang h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14343 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                             Review  Rating\n",
       "0          0  exceptional service nice all-around daughter s...       5\n",
       "1          1  beautiful relaxing jw marriott desert ridge re...       5\n",
       "2          2  great location great location 5 mins subway ta...       5\n",
       "3          3  pleased nice safe hotel, flower market hotel v...       3\n",
       "4          4  excellent hotel service great hotel excellent ...       4\n",
       "...      ...                                                ...     ...\n",
       "14338  14338  hotel madrid hotel perfect, location tiny quie...       5\n",
       "14339  14339  excellent hotel stay florence hotel chosen tri...       5\n",
       "14340  14340  great place relax know looking vacation book t...       4\n",
       "14341  14341  better just got week seattle loved minute, pac...       3\n",
       "14342  14342  stay clear, internet reservation friday rang h...       1\n",
       "\n",
       "[14343 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_df=pd.read_csv(\"train.csv\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>just superb rendezvous just perfect property s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>better close staten island ferry easy subway, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>enjoyed stay, just come long weekend barcelona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>muse great, muse hotel great, did n't hear noi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>conveniently located morning flight, family st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6143</th>\n",
       "      <td>6143</td>\n",
       "      <td>great hotel precruise great hotel arrived earl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6144</th>\n",
       "      <td>6144</td>\n",
       "      <td>great choice just returned nights grand hotel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6145</th>\n",
       "      <td>6145</td>\n",
       "      <td>overpriced tiny rooms kowloon past use date ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6146</th>\n",
       "      <td>6146</td>\n",
       "      <td>ok, agree said positive staff helpful rooms cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6147</th>\n",
       "      <td>6147</td>\n",
       "      <td>great location husband stayed new orleans 6/10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6148 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                             Review\n",
       "0        0  just superb rendezvous just perfect property s...\n",
       "1        1  better close staten island ferry easy subway, ...\n",
       "2        2  enjoyed stay, just come long weekend barcelona...\n",
       "3        3  muse great, muse hotel great, did n't hear noi...\n",
       "4        4  conveniently located morning flight, family st...\n",
       "...    ...                                                ...\n",
       "6143  6143  great hotel precruise great hotel arrived earl...\n",
       "6144  6144  great choice just returned nights grand hotel ...\n",
       "6145  6145  overpriced tiny rooms kowloon past use date ne...\n",
       "6146  6146  ok, agree said positive staff helpful rooms cl...\n",
       "6147  6147  great location husband stayed new orleans 6/10...\n",
       "\n",
       "[6148 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_df=pd.read_csv(\"test.csv\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=pd.read_pickle(\"stp_wrds.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rating_count=train_df.groupby(by='Rating').ID.count()\n",
    "rating_count.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating\n",
       "1     977\n",
       "2    1248\n",
       "3    1510\n",
       "4    4172\n",
       "5    6436\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby(by='Rating').ID.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove html links and entity references\n",
    "def html_references(texts):\n",
    "    texts = texts\n",
    "    # remove url - references to websites\n",
    "    url_remove  = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    texts  = re.sub(url_remove, '', texts)\n",
    "    # remove common html entity references in utf-8 as '&lt;', '&gt;', '&amp;'\n",
    "    entities_remove = r'&amp;|&gt;|&lt'\n",
    "    texts = re.sub(entities_remove, \"\", texts)\n",
    "    # split into words by white space\n",
    "    words = texts.split()\n",
    "    #convert to lower case\n",
    "    words = [word.lower() for word in words]\n",
    "    return \" \".join(words)\n",
    "train_df['Review'] = train_df['Review'].apply(lambda x : html_references(x))\n",
    "test_df['Review'] = test_df['Review'].apply(lambda x : html_references(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontraction(text):\n",
    "    # specific\n",
    "    text = re.sub(r\"won\\'t\", \" will not\", text)\n",
    "    text = re.sub(r\"won\\'t've\", \" will not have\", text)\n",
    "    text = re.sub(r\"can\\'t\", \" can not\", text)\n",
    "    text = re.sub(r\"don\\'t\", \" do not\", text)\n",
    "    \n",
    "    text = re.sub(r\"can\\'t've\", \" can not have\", text)\n",
    "    text = re.sub(r\"ma\\'am\", \" madam\", text)\n",
    "    text = re.sub(r\"let\\'s\", \" let us\", text)\n",
    "    text = re.sub(r\"ain\\'t\", \" am not\", text)\n",
    "    text = re.sub(r\"shan\\'t\", \" shall not\", text)\n",
    "    text = re.sub(r\"sha\\n't\", \" shall not\", text)\n",
    "    text = re.sub(r\"o\\'clock\", \" of the clock\", text)\n",
    "    text = re.sub(r\"y\\'all\", \" you all\", text)\n",
    "    # general\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"n\\'t've\", \" not have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'d've\", \" would have\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ll've\", \" will have\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    return text \n",
    "train_df['Review'] = train_df['Review'].apply(lambda x : decontraction(x))\n",
    "test_df['Review'] = test_df['Review'].apply(lambda x : decontraction(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "def filter_punctuations_etc(texts):\n",
    "    words = texts.split()\n",
    "    # prepare regex for char filtering\n",
    "    re_punc = re.compile( '[%s]' % re.escape(string.punctuation))\n",
    "    # remove punctuation from each word\n",
    "    words = [re_punc.sub('', w) for w in words]\n",
    "    # filter out non-printable characters\n",
    "    re_print = re.compile( '[^%s]' % re.escape(string.printable))\n",
    "    words = [re_print.sub(' ', w) for w in words]\n",
    "    return \" \".join(words)\n",
    "train_df['Review'] = train_df['Review'].apply(lambda x : filter_punctuations_etc(x))\n",
    "test_df['Review'] = test_df['Review'].apply(lambda x : filter_punctuations_etc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_alphanumeric(texts):\n",
    "    words = texts\n",
    "    # separate alphanumeric\n",
    "    words = re.findall(r\"[^\\W\\d_]+|\\d+\", words)\n",
    "    return \" \".join(words)\n",
    "train_df['Review'] = train_df['Review'].apply(lambda x : separate_alphanumeric(x))\n",
    "test_df['Review'] = test_df['Review'].apply(lambda x : separate_alphanumeric(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change repetitive characters\n",
    "def cont_rep_char(text):\n",
    "    tchr = text.group(0) \n",
    "    \n",
    "    if len(tchr) > 1:\n",
    "        return tchr[0:2] # take max of 2 consecutive letters\n",
    "def unique_char(rep, texts):\n",
    "    substitute = re.sub(r'(\\w)\\1+', rep, texts)\n",
    "    return substitute\n",
    "train_df['Review'] = (train_df['Review'].astype('str').apply(lambda x : unique_char(cont_rep_char, x)))\n",
    "test_df['Review'] = (test_df['Review'].astype('str').apply(lambda x : unique_char(cont_rep_char, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordninja\n",
      "  Downloading wordninja-2.0.0.tar.gz (541 kB)\n",
      "Building wheels for collected packages: wordninja\n",
      "  Building wheel for wordninja (setup.py): started\n",
      "  Building wheel for wordninja (setup.py): finished with status 'done'\n",
      "  Created wheel for wordninja: filename=wordninja-2.0.0-py3-none-any.whl size=541558 sha256=796a801a5bf0eed9e983ef7b00fee843769fde48ad64aed62d39baf10b2ada14\n",
      "  Stored in directory: c:\\users\\sathi\\appdata\\local\\pip\\cache\\wheels\\dd\\3f\\eb\\a2692e3d2b9deb1487b09ba4967dd6920bd5032bfd9ff7acfc\n",
      "Successfully built wordninja\n",
      "Installing collected packages: wordninja\n",
      "Successfully installed wordninja-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wordninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wordninja # !pip install wordninja\n",
    "def split_attached_words(text):\n",
    "    words = wordninja.split(text)\n",
    "    return\" \".join(words)\n",
    "train_df['Review'] = train_df['Review'].apply(lambda x : split_attached_words(x))\n",
    "test_df['Review'] = test_df['Review'].apply(lambda x : split_attached_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_shortwords(text):\n",
    "    # filter out stop words\n",
    "    words = text.split()\n",
    "    stop_words = set(stopwords.words( 'english' ))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    for word in words:\n",
    "        if word.isalpha():\n",
    "            words = [word for word in words if len(word) > 1 ]\n",
    "        else:\n",
    "            words = [word for word in words]\n",
    "    return\" \".join(words)\n",
    "train_df['Review'] = train_df['Review'].apply(lambda x : stopwords_shortwords(x))\n",
    "test_df['Review'] = test_df['Review'].apply(lambda x : stopwords_shortwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.5.5-py2.py3-none-any.whl (1.9 MB)\n",
      "Installing collected packages: pyspellchecker\n",
      "Successfully installed pyspellchecker-0.5.5\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20491, 4)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.concat([train_df,test_df])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "def correct_spellings(text):\n",
    "    corrected_text = []\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_text.append(spell.correction(word))\n",
    "        else:\n",
    "            corrected_text.append(word)\n",
    "    return \" \".join(corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review']=df['Review'].apply(lambda x : correct_spellings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pickle file for df\n",
    "with open(\"df.pkl\", \"wb\") as picklefile:\n",
    "         pickle.dump(df, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=df[[\"Review\",\"Rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD EMBEDDING USING ONE HOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['exceptional service nice around daughter stayed well priced hotel 99 night king suite weekend nights really impressed exceptionally welcoming service time reservation departure hotel employee talked really friendly eager help questions amazed day age shaped hotel pool tiny looked like fun kids hot tub exercise room well breakfast abundant make waffles add scrambled eggs bacon sausage fruit available bagels muffins oatmeal yogurt wanted morning sort long line waiting make waffles waiting scrambled eggs pick room really nice asked away freeway reading reviews earlier bit noisy hey city felt like deluxe room considering reasonable price nice bedding art walls really liked space needle bit window shuttle runs hourly reserve certain place certain time worked shuttle missed minute needed return space needle promptly paid cab fare asked definitely need stay near downtown seattle',\n",
       " 'beautiful relaxing marriott desert ridge resort outstanding accommodation business pleasure husband stayed business conference march 30 april 2005 enjoyed tremendously half hour drive airport hotel beautiful impressive marble entry fountain room balcony overlooked different pools lazy river golf course palm trees restaurants excellent service delicious food especially enjoyed merit age property manicured pristine staff friendly courteous spa immaculate massages wonderful felt pampered ju via ted want home reality rented convertible hertz property great time driving 20 min scottsdale tempe day trip perfect weather 82 degrees great time year visit golf spoke thought wonderful like visit children love pools lazy river highly recommend property',\n",
       " 'great location great location mins subway takes way blom ming dales soho perfect 10 mins walk macy easy walk times square breakfast gemini diner previous recommendation nd ave 35 th really good looking typical american diner experience guy gall and good breakfast staff helpful really nice problem heating fixed problem room quiet apart toilet cistern light sleeper bother complain times stayed ny far best location room huge studio',\n",
       " 'pleased nice safe hotel flower market hotel vast array restaurants main gay district hotel walking distance farthest walked slow walk anne frank house 3040 minutes corner new discover rooms small com fo table extremely clean staff helpful breakfast main dining room pricey euro 15 numerous cafes breakfast corner brandt square',\n",
       " 'excellent hotel service great hotel excellent location couple minutes walk duomo david corner essential tourist attractions close hand beautiful rooms staff really friendly especially breakfast dude loved stay visiting florence',\n",
       " 'beautiful beautiful beautiful hotel perfect thi perfect hotel stay stay girl desk help full room cozy reds mao go nhs best beds slept hotel time visit stay frenchman',\n",
       " 'enough spend night business trip stars hotel building ni sure stars hotel service position room nice big clean floor people really rude receptionist speak loudly phone scared car exiting box believe stars far away place',\n",
       " 'great place villa ix good quiet location walk beach really suitable swim nice walk easy close sem yak enjoy shopping good restaurants italian tr tory simple delicious crowded rented private villa bedrooms private swimming pool july 2007 children years loved decoration mix balinese design living room dining room outside big bathrooms swimming pool long swim balinese pave bal outside massages breakfast delicious day ordered lunch served villa food good balinese european disc especially german cooking owner german personal friendly help full stayed nights according short week better sure book villa ix',\n",
       " 'march 14 28 th 2007 wonderful relaxing vacation stayed catalonia march 14 28 2007 felt share thoughts appreciated shared age range 43 55 yrs thoroughly enjoyed property service wonderful grounds pretty accommodations comfortable food delicious drinks good bailey nice added touch let know wanted real bailey homemade concoction amazing far smile despite language barrier purpose trip relax beach went beautiful pool excursions hire juan door standing looking water left ba vary beach friends beach differences snorkelling reef gone snorkelling kind informative work great deal people think weeks long wanted stay longer despite fact ate drank relax beach beautiful despite past reviews ocean fine seagrass great snorkelling saw whales jumping water occasions absolutely amazing course seaweed nature beach crew morning cleaning seaweed washed night wanted umbrella close water 630 towels weather perfect 13 15 days half days rain guess lucky definitely recommend hotel looking star property want star property service resort holiday make matter room improvement expensive request accommodated better thanks staff catalonia wonderful vacation',\n",
       " 'fantastic value true gem stayed hotel husbands 40 th birthday given room overlooking canal st floor noise nothing stop sleeping breakfast excellent great place stay expensive city cafes 1015 euros breakfast rooms star hotel 910 enjoy']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = new_df['Review'].tolist()\n",
    "text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x21ee1e58988>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts(text)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=text\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "all_words = []\n",
    "for sent in corpus:\n",
    "    tokenize_word = word_tokenize(sent)\n",
    "    for word in tokenize_word:\n",
    "        all_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30120\n"
     ]
    }
   ],
   "source": [
    "unique_words = set(all_words)\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30121"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set vocabulary size\n",
    "vocab_size = len(unique_words) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedded_sentences = [one_hot(sent, vocab_size) for sent in corpus]\n",
    "print(embedded_sentences )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = lambda sentence: len(word_tokenize(sentence))\n",
    "longest_sentence = max(corpus, key=word_count)\n",
    "length_long_sentence = len(word_tokenize(longest_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18195 19502 13220 ...     0     0     0]\n",
      " [26380 18349  5289 ...     0     0     0]\n",
      " [16954 10025 16954 ...     0     0     0]\n",
      " ...\n",
      " [17044 11669  2565 ...     0     0     0]\n",
      " [28171  5409 15423 ...     0     0     0]\n",
      " [16954 10025  8318 ...     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "padded_sentences = pad_sequences(embedded_sentences, length_long_sentence, padding='post')\n",
    "print(padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "vect_size=300\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocab_size,vect_size,input_length=length_long_sentence))\n",
    "#model.add(GRU(units=32,dropout=0.2,recurrent_dropout=0.2))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv1D(64, 8, activation = 'relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(30, activation='relu'))\n",
    "\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=padded_sentences[:train_df.shape[0]]\n",
    "test=padded_sentences[train_df.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train (12191, 1896)\n",
      "Shape of Validation  (2152, 1896)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(train,train_df['Rating'].values,test_size=0.15)\n",
    "print('Shape of train',X_train.shape)\n",
    "print(\"Shape of Validation \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9752 samples, validate on 2439 samples\n",
      "Epoch 1/10\n",
      "9752/9752 - 318s - loss: 1.4602 - acc: 0.3977 - val_loss: 1.4357 - val_acc: 0.4502\n",
      "Epoch 2/10\n",
      "9752/9752 - 419s - loss: 1.3619 - acc: 0.4471 - val_loss: 1.4449 - val_acc: 0.4502\n",
      "Epoch 3/10\n",
      "9752/9752 - 397s - loss: 1.3573 - acc: 0.4470 - val_loss: 1.4355 - val_acc: 0.4502\n",
      "Epoch 4/10\n",
      "9752/9752 - 347s - loss: 1.3596 - acc: 0.4467 - val_loss: 1.4358 - val_acc: 0.4502\n",
      "Epoch 5/10\n",
      "9752/9752 - 313s - loss: 1.3579 - acc: 0.4469 - val_loss: 1.4448 - val_acc: 0.4502\n",
      "Epoch 6/10\n",
      "9752/9752 - 346s - loss: 1.3571 - acc: 0.4471 - val_loss: 1.4434 - val_acc: 0.4502\n",
      "Epoch 7/10\n",
      "9752/9752 - 347s - loss: 1.3580 - acc: 0.4471 - val_loss: 1.4310 - val_acc: 0.4502\n",
      "Epoch 8/10\n",
      "9752/9752 - 344s - loss: 1.3590 - acc: 0.4469 - val_loss: 1.4536 - val_acc: 0.4502\n",
      "Epoch 9/10\n",
      "9752/9752 - 333s - loss: 1.3583 - acc: 0.4471 - val_loss: 1.4406 - val_acc: 0.4502\n",
      "Epoch 10/10\n",
      "9752/9752 - 322s - loss: 1.3566 - acc: 0.4471 - val_loss: 1.4474 - val_acc: 0.4502\n",
      "Wall time: 58min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Embed_model=model.fit(X_train, y_train, epochs = 10, validation_split = 0.2,verbose=2,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2152/2152 - 14s - loss: 1.2364 - acc: 0.5232\n",
      "Test accuracy: 0.5232342\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                       batch_size=128, verbose=2)\n",
    "\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.6001248e-06, 1.3662323e-07, 1.9371095e-05, 4.4283914e-04,\n",
       "        2.3296194e-02, 9.7623891e-01],\n",
       "       [6.1382730e-06, 1.7426689e-03, 5.4103110e-02, 4.2303586e-01,\n",
       "        2.7700743e-01, 2.4410482e-01],\n",
       "       [9.4806010e-06, 2.0867859e-05, 1.2283328e-03, 7.8137172e-03,\n",
       "        9.9232741e-02, 8.9169490e-01],\n",
       "       ...,\n",
       "       [6.9960795e-04, 3.5259280e-01, 3.3373076e-01, 2.6717356e-01,\n",
       "        3.9513327e-02, 6.2899091e-03],\n",
       "       [6.5669685e-04, 9.3390152e-04, 1.3017022e-02, 1.8092790e-01,\n",
       "        3.5425088e-01, 4.5021358e-01],\n",
       "       [6.0453359e-04, 4.7071544e-03, 5.0290946e-02, 2.1185255e-01,\n",
       "        3.5333773e-01, 3.7920710e-01]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aplly test data and make pediction\n",
    "y_pred=model.predict(test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 5, ..., 1, 5, 5], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD EMBEDDING USING GLOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glove vectorization\n",
    "def create_corpus(df):\n",
    "    corpus=[]\n",
    "    for text in tqdm(df['Review']):\n",
    "        words=[word.lower() for word in word_tokenize(text) if((word.isalpha()==1) & (word not in stop))]\n",
    "        corpus.append(words)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20491/20491 [00:36<00:00, 557.55it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus=create_corpus(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict={}\n",
    "with open('glove.6B.100d.txt','rb') as f:\n",
    "    for line in f:\n",
    "        values=line.split()\n",
    "        word=values[0]\n",
    "        vectors=np.asarray(values[1:],'float32')\n",
    "        embedding_dict[word]=vectors\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN=150\n",
    "tokenizer_obj=Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(corpus)\n",
    "sequences=tokenizer_obj.texts_to_sequences(corpus)\n",
    "\n",
    "review_pad=pad_sequences(sequences,maxlen=MAX_LEN,truncating='post',padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 27735\n"
     ]
    }
   ],
   "source": [
    "word_index=tokenizer_obj.word_index\n",
    "print('Number of unique words:',len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27735/27735 [00:00<00:00, 579345.11it/s]\n"
     ]
    }
   ],
   "source": [
    "num_words=len(word_index)+1\n",
    "embedding_matrix=np.zeros((num_words,100))\n",
    "\n",
    "for word,i in tqdm(word_index.items()):\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    \n",
    "    emb_vec=embedding_dict.get(word)\n",
    "    if emb_vec is not None:\n",
    "        embedding_matrix[i]=emb_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.initializers import Constant\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "glove_model=Sequential()\n",
    "\n",
    "embedding=Embedding(num_words,100,embeddings_initializer=Constant(embedding_matrix),\n",
    "                   input_length=MAX_LEN,trainable=False)\n",
    "\n",
    "glove_model.add(embedding)\n",
    "glove_model.add(Dropout(0.5))\n",
    "glove_model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "glove_model.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimzer=Adam(learning_rate=1e-5)\n",
    "\n",
    "glove_model.compile(loss='sparse_categorical_crossentropy',optimizer=optimzer,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=review_pad[:train_df.shape[0]]\n",
    "test=review_pad[train_df.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train (12191, 150)\n",
      "Shape of Validation  (2152, 150)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(train,train_df['Rating'].values,test_size=0.15)\n",
    "print('Shape of train',X_train.shape)\n",
    "print(\"Shape of Validation \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12191 samples, validate on 2152 samples\n",
      "WARNING:tensorflow:From C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/10\n",
      "12191/12191 - 323s - loss: 1.5398 - acc: 0.4517 - val_loss: 1.4268 - val_acc: 0.4243\n",
      "Epoch 2/10\n",
      "12191/12191 - 295s - loss: 1.3742 - acc: 0.4529 - val_loss: 1.3931 - val_acc: 0.4243\n",
      "Epoch 3/10\n",
      "12191/12191 - 298s - loss: 1.3577 - acc: 0.4528 - val_loss: 1.3811 - val_acc: 0.4243\n",
      "Epoch 4/10\n",
      "12191/12191 - 319s - loss: 1.3536 - acc: 0.4530 - val_loss: 1.3801 - val_acc: 0.4243\n",
      "Epoch 5/10\n",
      "12191/12191 - 309s - loss: 1.3523 - acc: 0.4531 - val_loss: 1.3788 - val_acc: 0.4243\n",
      "Epoch 6/10\n",
      "12191/12191 - 320s - loss: 1.3514 - acc: 0.4532 - val_loss: 1.3783 - val_acc: 0.4243\n",
      "Epoch 7/10\n",
      "12191/12191 - 318s - loss: 1.3505 - acc: 0.4529 - val_loss: 1.3762 - val_acc: 0.4243\n",
      "Epoch 8/10\n",
      "12191/12191 - 320s - loss: 1.3502 - acc: 0.4530 - val_loss: 1.3773 - val_acc: 0.4243\n",
      "Epoch 9/10\n",
      "12191/12191 - 381s - loss: 1.3494 - acc: 0.4530 - val_loss: 1.3774 - val_acc: 0.4243\n",
      "Epoch 10/10\n",
      "12191/12191 - 357s - loss: 1.3487 - acc: 0.4530 - val_loss: 1.3769 - val_acc: 0.4243\n"
     ]
    }
   ],
   "source": [
    "history=glove_model.fit(X_train,y_train,batch_size=4,epochs=10,validation_data=(X_test,y_test),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2152/2152 - 1s - loss: 1.3769 - acc: 0.4243\n",
      "Test accuracy: 0.4242565\n"
     ]
    }
   ],
   "source": [
    "score, acc = glove_model.evaluate(X_test, y_test,\n",
    "                       batch_size=128, verbose=2)\n",
    "\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model building using supervised machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle(\"df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1=df[:train_df.shape[0]]\n",
    "test1=df[train_df.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>target_relabeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>exceptional service nice around daughter staye...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>beautiful relaxing marriott desert ridge resor...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>great location great location mins subway take...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>pleased nice safe hotel flower market hotel va...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>excellent hotel service great hotel excellent ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14338</th>\n",
       "      <td>14338</td>\n",
       "      <td>hotel madrid hotel perfect location tiny quiet...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14339</th>\n",
       "      <td>14339</td>\n",
       "      <td>excellent hotel stay florence hotel chosen tri...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14340</th>\n",
       "      <td>14340</td>\n",
       "      <td>great place relax know looking vacation book t...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14341</th>\n",
       "      <td>14341</td>\n",
       "      <td>better got week seattle loved minute pacific p...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14342</th>\n",
       "      <td>14342</td>\n",
       "      <td>stay clear internet reservation friday rang ho...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14343 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                             Review  Rating  \\\n",
       "0          0  exceptional service nice around daughter staye...     5.0   \n",
       "1          1  beautiful relaxing marriott desert ridge resor...     5.0   \n",
       "2          2  great location great location mins subway take...     5.0   \n",
       "3          3  pleased nice safe hotel flower market hotel va...     3.0   \n",
       "4          4  excellent hotel service great hotel excellent ...     4.0   \n",
       "...      ...                                                ...     ...   \n",
       "14338  14338  hotel madrid hotel perfect location tiny quiet...     5.0   \n",
       "14339  14339  excellent hotel stay florence hotel chosen tri...     5.0   \n",
       "14340  14340  great place relax know looking vacation book t...     4.0   \n",
       "14341  14341  better got week seattle loved minute pacific p...     3.0   \n",
       "14342  14342  stay clear internet reservation friday rang ho...     1.0   \n",
       "\n",
       "       target_relabeled  \n",
       "0                   5.0  \n",
       "1                   5.0  \n",
       "2                   5.0  \n",
       "3                   3.0  \n",
       "4                   4.0  \n",
       "...                 ...  \n",
       "14338               5.0  \n",
       "14339               5.0  \n",
       "14340               4.0  \n",
       "14341               3.0  \n",
       "14342               1.0  \n",
       "\n",
       "[14343 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>target_relabeled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>superb rendezvous perfect property singapore f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>better close staten island ferry easy subway r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>enjoyed stay come long weekend barcelona staye...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>muse great muse hotel great hear noise reviewe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>conveniently located morning flight family sta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6143</th>\n",
       "      <td>6143</td>\n",
       "      <td>great hotel pre cruise great hotel arrived ear...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6144</th>\n",
       "      <td>6144</td>\n",
       "      <td>great choice returned nights grand hotel franc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6145</th>\n",
       "      <td>6145</td>\n",
       "      <td>overpriced tiny rooms kowloon past use date ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6146</th>\n",
       "      <td>6146</td>\n",
       "      <td>ok agree said positive staff helpful rooms cle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6147</th>\n",
       "      <td>6147</td>\n",
       "      <td>great location husband stayed new orleans 6106...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6148 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                             Review  Rating  \\\n",
       "0        0  superb rendezvous perfect property singapore f...     NaN   \n",
       "1        1  better close staten island ferry easy subway r...     NaN   \n",
       "2        2  enjoyed stay come long weekend barcelona staye...     NaN   \n",
       "3        3  muse great muse hotel great hear noise reviewe...     NaN   \n",
       "4        4  conveniently located morning flight family sta...     NaN   \n",
       "...    ...                                                ...     ...   \n",
       "6143  6143  great hotel pre cruise great hotel arrived ear...     NaN   \n",
       "6144  6144  great choice returned nights grand hotel franc...     NaN   \n",
       "6145  6145  overpriced tiny rooms kowloon past use date ne...     NaN   \n",
       "6146  6146  ok agree said positive staff helpful rooms cle...     NaN   \n",
       "6147  6147  great location husband stayed new orleans 6106...     NaN   \n",
       "\n",
       "      target_relabeled  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  \n",
       "...                ...  \n",
       "6143               NaN  \n",
       "6144               NaN  \n",
       "6145               NaN  \n",
       "6146               NaN  \n",
       "6147               NaN  \n",
       "\n",
       "[6148 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data for trainung and testing : train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train1['Review']\n",
    "y=train1['Rating']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10757,)\n",
      "(3586,)\n",
      "(10757,)\n",
      "(3586,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing data\n",
    "test_X=test1[\"Review\"]\n",
    "test_y=y[0:6148]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Representation.Bag of word approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=pd.read_pickle(\"stp_wrds.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=CountVectorizer(tokenizer=word_tokenize,stop_words=stop, max_df=0.75, lowercase=False, ngram_range=(1,2))\n",
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3586x549336 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 385262 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building: Train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following four models:\n",
    "\n",
    "Logistic Regression\n",
    "\n",
    "(Multinomial) Naive Bayes\n",
    "\n",
    "Linear Support Vector Machine\n",
    "\n",
    "Xgboost\n",
    "\n",
    "SGD classifier\n",
    "\n",
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_Classifier_result(X, y,X_test,y_test):\n",
    "    NB = MultinomialNB()\n",
    "    NB.fit(X, y)\n",
    "    prediction = NB.predict(X_test)\n",
    "    print(classification_report(prediction, y_test))\n",
    "    print(metrics.accuracy_score(y_test,prediction))\n",
    "    print(\"NB Classifier result:\")\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LG_Classifier_result(X, y,X_test,y_test):\n",
    "    LG = LogisticRegression()\n",
    "    LG.fit(X,y)\n",
    "    prediction = LG.predict(X_test)\n",
    "    print(classification_report(prediction, y_test))\n",
    "    print(metrics.accuracy_score(y_test,prediction))\n",
    "    print(\" LG Classifier result:\")\n",
    "     \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_Classifier_result(X, y,X_test,y_test):\n",
    "    SVM = LinearSVC()\n",
    "    SVM.fit(X,y)\n",
    "    prediction = SVM.predict(X_test)\n",
    "    print(classification_report(prediction, y_test))\n",
    "    print(metrics.accuracy_score(y_test,prediction))\n",
    "    print(\" SVM Classifier result:\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XG_Classifier_result(X, y,X_test,y_test):\n",
    "    XGB = XGBClassifier(objective='multi:softmax', n_estimators=100, learning_rate=0.3, max_depth=4, subsample=0.8, n_iter_no_change=2, verbosity=1)\n",
    "    XGB.fit(X,y)\n",
    "    prediction = XGB.predict(X_test)\n",
    "    print(classification_report(prediction, y_test))\n",
    "    print(metrics.accuracy_score(y_test,prediction))\n",
    "    print(\" XGB Classifier result:\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_Classifier_result(X, y,X_test,y_test):\n",
    "    SGD = SGDClassifier(max_iter=1000, tol=0.01)\n",
    "    SGD.fit(X,y)\n",
    "    prediction = SGD.predict(X_test)\n",
    "    print(classification_report(prediction, y_test))\n",
    "    print(metrics.accuracy_score(y_test,prediction))\n",
    "    print(\" SGD Classifier result:\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def RF_Classifier_result(X, y,X_test,y_test):\n",
    "    RF = RandomForestClassifier(n_estimators=100, max_depth=100, min_samples_split=10, n_jobs=-1, verbose=0)\n",
    "    RF.fit(X,y)\n",
    "    prediction = RF.predict(X_test)\n",
    "    print(classification_report(prediction, y_test))\n",
    "    print(metrics.accuracy_score(y_test,prediction))\n",
    "    print(\" RF Classifier result:\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model bulding : Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_Classifier_result(X, y,X_test,y_test):\n",
    "    NB = MultinomialNB()\n",
    "    NB.fit(X, y)\n",
    "    prediction = NB.predict(X_test)\n",
    "       \n",
    "    print(\"NB Classifier test data Accuracy:\")\n",
    "    print(metrics.accuracy_score(y_test,prediction))\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LG_Classifier_result(X, y,X_test,y_test):\n",
    "    LG = LogisticRegression()\n",
    "    LG.fit(X,y)\n",
    "    prediction = LG.predict(X_test)\n",
    "    print(\" LG Classifier Accuracy:\")\n",
    "    print(metrics.accuracy_score(y_test,prediction))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_Classifier_result(X, y,X_test,y_test):\n",
    "    SVM = LinearSVC()\n",
    "    SVM.fit(X,y)\n",
    "    prediction = SVM.predict(X_test)\n",
    "    print(\" SVM Classifier Accuracy:\")\n",
    "    print(metrics.accuracy_score(y_test,prediction))\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XG_Classifier_result(X, y,X_test,y_test):\n",
    "    XGB = XGBClassifier(objective='multi:softmax', n_estimators=100, learning_rate=0.3, max_depth=4, subsample=0.8, n_iter_no_change=2, verbosity=1)\n",
    "    XGB.fit(X,y)\n",
    "    prediction = XGB.predict(X_test)\n",
    "    print(\" XGB Classifier Accuracy:\")\n",
    "    print(metrics.accuracy_score(y_test,prediction))\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_Classifier_result(X, y,X_test,y_test):\n",
    "    SGD = SGDClassifier(max_iter=1000, tol=0.01)\n",
    "    SGD.fit(X,y)\n",
    "    prediction = SGD.predict(X_test)\n",
    "    print(\" SGD Classifier Accuracy:\")\n",
    "    print(metrics.accuracy_score(y_test,prediction))\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_Classifier_result(X, y,X_test,y_test):\n",
    "    RF = RandomForestClassifier(n_estimators=100, max_depth=100, min_samples_split=10, n_jobs=-1, verbose=0)\n",
    "    RF.fit(X,y)\n",
    "    prediction = RF.predict(X_test)\n",
    "    print(\" RF Classifier Accuracy:\")\n",
    "    print(metrics.accuracy_score(y_test,prediction))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Oversampling Imbalanced Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to improve the performance?\n",
    "\n",
    "Re-sampling Dataset\n",
    "\n",
    "To make our dataset balanced there are two ways to do so:\n",
    "\n",
    "Under-sampling: Remove samples from over-represented classes ; use this if you have huge dataset\n",
    "\n",
    "Over-sampling: Add more samples from under-represented classes; use this if you have small dataset\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random oversampling involves randomly duplicating examples from the minority class and adding them to the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomOverSampler\n",
    "\n",
    "SMOTE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14836, 549336) (14836,)\n"
     ]
    }
   ],
   "source": [
    "#smote\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE('minority')\n",
    "\n",
    "X_sm, y_sm = smote.fit_sample(X_train_dtm, y_train)\n",
    "print(X_sm.shape, y_sm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24075, 549336) (24075,)\n"
     ]
    }
   ],
   "source": [
    "#Random oversampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "X_ros, y_ros = ros.fit_sample(X_train_dtm, y_train)\n",
    "print(X_ros.shape, y_ros.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3680, 549336) (3680,)\n"
     ]
    }
   ],
   "source": [
    "#RandomUnderSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "X_rus, y_rus= rus.fit_sample(X_train_dtm, y_train)\n",
    "print(X_rus.shape, y_rus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TomekLinks\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "tl = TomekLinks('majority')\n",
    "X_tl, y_tl = tl.fit_sample(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTETomek\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek('auto')\n",
    "X_smt, y_smt = smt.fit_sample(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasing imbalanced data(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.02      1.00      0.05         6\n",
      "         2.0       0.01      0.29      0.01         7\n",
      "         3.0       0.00      0.00      0.00         0\n",
      "         4.0       0.16      0.27      0.20       608\n",
      "         5.0       0.97      0.53      0.69      2965\n",
      "\n",
      "    accuracy                           0.49      3586\n",
      "   macro avg       0.23      0.42      0.19      3586\n",
      "weighted avg       0.83      0.49      0.60      3586\n",
      "\n",
      "0.4860568878973787\n",
      "NB Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.59      0.59      0.59       244\n",
      "         2.0       0.29      0.42      0.34       217\n",
      "         3.0       0.27      0.41      0.32       253\n",
      "         4.0       0.47      0.47      0.47      1022\n",
      "         5.0       0.79      0.70      0.74      1850\n",
      "\n",
      "    accuracy                           0.59      3586\n",
      "   macro avg       0.48      0.52      0.49      3586\n",
      "weighted avg       0.62      0.59      0.60      3586\n",
      "\n",
      "0.5878416062465143\n",
      " LG Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.61      0.59      0.60       251\n",
      "         2.0       0.25      0.40      0.31       199\n",
      "         3.0       0.25      0.37      0.30       262\n",
      "         4.0       0.44      0.45      0.44      1007\n",
      "         5.0       0.78      0.68      0.73      1867\n",
      "\n",
      "    accuracy                           0.57      3586\n",
      "   macro avg       0.47      0.50      0.48      3586\n",
      "weighted avg       0.61      0.57      0.59      3586\n",
      "\n",
      "0.5708310094813163\n",
      " SVM Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.59      0.59      0.59       238\n",
      "         2.0       0.21      0.40      0.28       171\n",
      "         3.0       0.17      0.42      0.24       153\n",
      "         4.0       0.47      0.45      0.46      1065\n",
      "         5.0       0.82      0.68      0.75      1959\n",
      "\n",
      "    accuracy                           0.58      3586\n",
      "   macro avg       0.45      0.51      0.46      3586\n",
      "weighted avg       0.65      0.58      0.61      3586\n",
      "\n",
      "0.5828220858895705\n",
      " XGB Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.63      0.57      0.60       263\n",
      "         2.0       0.28      0.38      0.32       229\n",
      "         3.0       0.19      0.33      0.24       221\n",
      "         4.0       0.45      0.47      0.46       972\n",
      "         5.0       0.81      0.69      0.74      1901\n",
      "\n",
      "    accuracy                           0.58      3586\n",
      "   macro avg       0.47      0.49      0.47      3586\n",
      "weighted avg       0.62      0.58      0.60      3586\n",
      "\n",
      "0.5786391522587842\n",
      " SGD Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.11      0.87      0.19        30\n",
      "         2.0       0.00      1.00      0.01         1\n",
      "         3.0       0.00      0.00      0.00         0\n",
      "         4.0       0.07      0.32      0.11       224\n",
      "         5.0       0.98      0.48      0.64      3331\n",
      "\n",
      "    accuracy                           0.47      3586\n",
      "   macro avg       0.23      0.53      0.19      3586\n",
      "weighted avg       0.92      0.47      0.61      3586\n",
      "\n",
      "0.4712771890686001\n",
      " RF Classifier result:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_train_dtm, y_train,X_test_dtm,y_test))\n",
    "print(LG_Classifier_result(X_train_dtm, y_train,X_test_dtm,y_test))\n",
    "print(SVM_Classifier_result(X_train_dtm, y_train,X_test_dtm,y_test))\n",
    "print(XG_Classifier_result(X_train_dtm, y_train,X_test_dtm,y_test))\n",
    "print(SGD_Classifier_result(X_train_dtm, y_train,X_test_dtm,y_test))\n",
    "print(RF_Classifier_result(X_train_dtm, y_train,X_test_dtm,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6148x549336 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 644215 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pass test  data and check the accuracy\n",
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "\n",
    "X_test_data = vect.transform(test_X)\n",
    "X_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Classifier test data Accuracy:\n",
      "0.4201366297983084\n",
      "None\n",
      " LG Classifier Accuracy:\n",
      "0.3282368249837345\n",
      "None\n",
      " SVM Classifier Accuracy:\n",
      "0.328562134027326\n",
      "None\n",
      " XGB Classifier Accuracy:\n",
      "0.3445022771633051\n",
      "None\n",
      " SGD Classifier Accuracy:\n",
      "0.32286922576447624\n",
      "None\n",
      " RF Classifier Accuracy:\n",
      "0.4386792452830189\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Check the accuracy of test data\n",
    "print(NB_Classifier_result(X_train_dtm, y_train,X_test_data,test_y))\n",
    "print(LG_Classifier_result(X_train_dtm, y_train,X_test_data,test_y))\n",
    "print(SVM_Classifier_result(X_train_dtm, y_train,X_test_data,test_y))\n",
    "print(XG_Classifier_result(X_train_dtm, y_train,X_test_data,test_y))\n",
    "print(SGD_Classifier_result(X_train_dtm, y_train,X_test_data,test_y))\n",
    "print(RF_Classifier_result(X_train_dtm, y_train,X_test_data,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and evaluating a model using balanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passing SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.23      0.92      0.37        61\n",
      "         2.0       0.00      1.00      0.01         1\n",
      "         3.0       0.00      0.00      0.00         0\n",
      "         4.0       0.16      0.28      0.21       577\n",
      "         5.0       0.97      0.53      0.69      2947\n",
      "\n",
      "    accuracy                           0.50      3586\n",
      "   macro avg       0.27      0.55      0.25      3586\n",
      "weighted avg       0.83      0.50      0.60      3586\n",
      "\n",
      "0.4997211377579476\n",
      "NB Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.64      0.45      0.53       341\n",
      "         2.0       0.28      0.41      0.33       213\n",
      "         3.0       0.28      0.42      0.34       256\n",
      "         4.0       0.47      0.49      0.48       974\n",
      "         5.0       0.79      0.71      0.75      1802\n",
      "\n",
      "    accuracy                           0.59      3586\n",
      "   macro avg       0.49      0.50      0.49      3586\n",
      "weighted avg       0.62      0.59      0.60      3586\n",
      "\n",
      "0.5883993307306191\n",
      " LG Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.65      0.41      0.50       383\n",
      "         2.0       0.24      0.37      0.29       209\n",
      "         3.0       0.23      0.36      0.28       252\n",
      "         4.0       0.42      0.46      0.44       942\n",
      "         5.0       0.77      0.69      0.73      1800\n",
      "\n",
      "    accuracy                           0.56      3586\n",
      "   macro avg       0.46      0.46      0.45      3586\n",
      "weighted avg       0.60      0.56      0.57      3586\n",
      "\n",
      "0.558282208588957\n",
      " SVM Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.59      0.61      0.60       233\n",
      "         2.0       0.21      0.39      0.28       173\n",
      "         3.0       0.15      0.39      0.22       151\n",
      "         4.0       0.48      0.45      0.46      1093\n",
      "         5.0       0.81      0.68      0.74      1936\n",
      "\n",
      "    accuracy                           0.58      3586\n",
      "   macro avg       0.45      0.50      0.46      3586\n",
      "weighted avg       0.64      0.58      0.60      3586\n",
      "\n",
      "0.5789180145008366\n",
      " XGB Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.63      0.34      0.45       441\n",
      "         2.0       0.26      0.37      0.31       228\n",
      "         3.0       0.20      0.38      0.27       209\n",
      "         4.0       0.45      0.46      0.46      1003\n",
      "         5.0       0.74      0.70      0.72      1705\n",
      "\n",
      "    accuracy                           0.55      3586\n",
      "   macro avg       0.46      0.45      0.44      3586\n",
      "weighted avg       0.58      0.55      0.56      3586\n",
      "\n",
      "0.5501952035694367\n",
      " SGD Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.52      0.35      0.42       358\n",
      "         2.0       0.00      0.00      0.00         0\n",
      "         3.0       0.00      0.00      0.00         0\n",
      "         4.0       0.01      0.28      0.02        46\n",
      "         5.0       0.95      0.48      0.64      3182\n",
      "\n",
      "    accuracy                           0.47      3586\n",
      "   macro avg       0.30      0.22      0.22      3586\n",
      "weighted avg       0.90      0.47      0.61      3586\n",
      "\n",
      "0.46820970440602344\n",
      " RF Classifier result:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_sm, y_sm,X_test_dtm,y_test))\n",
    "print(LG_Classifier_result(X_sm, y_sm,X_test_dtm,y_test))\n",
    "print(SVM_Classifier_result(X_sm, y_sm,X_test_dtm,y_test))\n",
    "print(XG_Classifier_result(X_sm, y_sm,X_test_dtm,y_test))\n",
    "print(SGD_Classifier_result(X_sm, y_sm,X_test_dtm,y_test))\n",
    "print(RF_Classifier_result(X_sm, y_sm,X_test_dtm,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Classifier test data Accuracy:\n",
      "0.41672088484059855\n",
      "None\n",
      " LG Classifier Accuracy:\n",
      "0.3217306441119063\n",
      "None\n",
      " SVM Classifier Accuracy:\n",
      "0.3160377358490566\n",
      "None\n",
      " XGB Classifier Accuracy:\n",
      "0.3441769681197137\n",
      "None\n",
      " SGD Classifier Accuracy:\n",
      "0.32075471698113206\n",
      "None\n",
      " RF Classifier Accuracy:\n",
      "0.41135328562134027\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#accuracy of test data\n",
    "print(NB_Classifier_result(X_sm, y_sm,X_test_data,test_y))\n",
    "print(LG_Classifier_result(X_sm, y_sm,X_test_data,test_y))\n",
    "print(SVM_Classifier_result(X_sm, y_sm,X_test_data,test_y))\n",
    "print(XG_Classifier_result(X_sm, y_sm,X_test_data,test_y))\n",
    "print(SGD_Classifier_result(X_sm, y_sm,X_test_data,test_y))\n",
    "print(RF_Classifier_result(X_sm, y_sm,X_test_data,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passing Random over sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.52      0.55       270\n",
      "           2       0.38      0.33      0.35       368\n",
      "           3       0.34      0.35      0.34       353\n",
      "           4       0.36      0.55      0.43       671\n",
      "           5       0.81      0.66      0.73      1622\n",
      "\n",
      "    accuracy                           0.56      3284\n",
      "   macro avg       0.49      0.48      0.48      3284\n",
      "weighted avg       0.60      0.56      0.57      3284\n",
      "\n",
      "0.5566382460414129\n",
      "(0.5566382460414129, '              precision    recall  f1-score   support\\n\\n           1       0.59      0.52      0.55       270\\n           2       0.38      0.33      0.35       368\\n           3       0.34      0.35      0.34       353\\n           4       0.36      0.55      0.43       671\\n           5       0.81      0.66      0.73      1622\\n\\n    accuracy                           0.56      3284\\n   macro avg       0.49      0.48      0.48      3284\\nweighted avg       0.60      0.56      0.57      3284\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LG Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.58      0.57      0.57       244\n",
      "           2       0.34      0.34      0.34       321\n",
      "           3       0.35      0.30      0.32       417\n",
      "           4       0.47      0.51      0.49       959\n",
      "           5       0.71      0.70      0.71      1343\n",
      "\n",
      "    accuracy                           0.55      3284\n",
      "   macro avg       0.49      0.48      0.49      3284\n",
      "weighted avg       0.55      0.55      0.55      3284\n",
      "\n",
      "0.5493300852618758\n",
      "(0.5493300852618758, '              precision    recall  f1-score   support\\n\\n           1       0.58      0.57      0.57       244\\n           2       0.34      0.34      0.34       321\\n           3       0.35      0.30      0.32       417\\n           4       0.47      0.51      0.49       959\\n           5       0.71      0.70      0.71      1343\\n\\n    accuracy                           0.55      3284\\n   macro avg       0.49      0.48      0.49      3284\\nweighted avg       0.55      0.55      0.55      3284\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.49      0.45       205\n",
      "           2       0.28      0.30      0.29       294\n",
      "           3       0.30      0.27      0.28       396\n",
      "           4       0.44      0.45      0.45      1014\n",
      "           5       0.68      0.66      0.67      1375\n",
      "\n",
      "    accuracy                           0.51      3284\n",
      "   macro avg       0.42      0.43      0.43      3284\n",
      "weighted avg       0.51      0.51      0.51      3284\n",
      "\n",
      "0.5054811205846529\n",
      "(0.5054811205846529, '              precision    recall  f1-score   support\\n\\n           1       0.42      0.49      0.45       205\\n           2       0.28      0.30      0.29       294\\n           3       0.30      0.27      0.28       396\\n           4       0.44      0.45      0.45      1014\\n           5       0.68      0.66      0.67      1375\\n\\n    accuracy                           0.51      3284\\n   macro avg       0.42      0.43      0.43      3284\\nweighted avg       0.51      0.51      0.51      3284\\n')\n",
      " XGB Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.48      0.54       316\n",
      "           2       0.34      0.35      0.35       304\n",
      "           3       0.33      0.31      0.32       383\n",
      "           4       0.48      0.56      0.52       886\n",
      "           5       0.75      0.71      0.73      1395\n",
      "\n",
      "    accuracy                           0.57      3284\n",
      "   macro avg       0.50      0.48      0.49      3284\n",
      "weighted avg       0.58      0.57      0.57      3284\n",
      "\n",
      "0.567904993909866\n",
      "(0.567904993909866, '              precision    recall  f1-score   support\\n\\n           1       0.63      0.48      0.54       316\\n           2       0.34      0.35      0.35       304\\n           3       0.33      0.31      0.32       383\\n           4       0.48      0.56      0.52       886\\n           5       0.75      0.71      0.73      1395\\n\\n    accuracy                           0.57      3284\\n   macro avg       0.50      0.48      0.49      3284\\nweighted avg       0.58      0.57      0.57      3284\\n')\n",
      " SGD Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.51      0.53       260\n",
      "           2       0.30      0.31      0.30       310\n",
      "           3       0.31      0.28      0.29       407\n",
      "           4       0.39      0.51      0.44       794\n",
      "           5       0.75      0.66      0.70      1513\n",
      "\n",
      "    accuracy                           0.53      3284\n",
      "   macro avg       0.46      0.45      0.45      3284\n",
      "weighted avg       0.55      0.53      0.54      3284\n",
      "\n",
      "0.5292326431181485\n",
      "(0.5292326431181485, '              precision    recall  f1-score   support\\n\\n           1       0.56      0.51      0.53       260\\n           2       0.30      0.31      0.30       310\\n           3       0.31      0.28      0.29       407\\n           4       0.39      0.51      0.44       794\\n           5       0.75      0.66      0.70      1513\\n\\n    accuracy                           0.53      3284\\n   macro avg       0.46      0.45      0.45      3284\\nweighted avg       0.55      0.53      0.54      3284\\n')\n",
      " RF Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.54      0.61       315\n",
      "           2       0.19      0.43      0.26       137\n",
      "           3       0.15      0.46      0.23       123\n",
      "           4       0.47      0.54      0.50       905\n",
      "           5       0.86      0.63      0.73      1804\n",
      "\n",
      "    accuracy                           0.58      3284\n",
      "   macro avg       0.48      0.52      0.47      3284\n",
      "weighted avg       0.68      0.58      0.62      3284\n",
      "\n",
      "0.5828258221680876\n",
      "(0.5828258221680876, '              precision    recall  f1-score   support\\n\\n           1       0.71      0.54      0.61       315\\n           2       0.19      0.43      0.26       137\\n           3       0.15      0.46      0.23       123\\n           4       0.47      0.54      0.50       905\\n           5       0.86      0.63      0.73      1804\\n\\n    accuracy                           0.58      3284\\n   macro avg       0.48      0.52      0.47      3284\\nweighted avg       0.68      0.58      0.62      3284\\n')\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_ros, y_ros,X_test_dtm,y_test))\n",
    "print(LG_Classifier_result(X_ros, y_ros,X_test_dtm,y_test))\n",
    "print(SVM_Classifier_result(X_ros, y_ros,X_test_dtm,y_test))\n",
    "print(XG_Classifier_result(X_ros, y_ros,X_test_dtm,y_test))\n",
    "print(SGD_Classifier_result(X_ros, y_ros,X_test_dtm,y_test))\n",
    "print(RF_Classifier_result(X_ros, y_ros,X_test_dtm,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic Regression :0.5493300852618758\n",
    "\n",
    "(Multinomial) Naive Bayes : 0.5566382460414129\n",
    "\n",
    "Linear Support Vector Machine : 0.5054811205846529\n",
    "\n",
    "Xgboost : 0.567904993909866\n",
    "\n",
    "SGD classifier : 0.5292326431181485\n",
    "\n",
    "Random Forest :  0.5828258221680876"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# passing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Classifier test data Accuracy:\n",
      "0.31766428106701367\n",
      "None\n",
      " LG Classifier Accuracy:\n",
      "0.31994144437215355\n",
      "None\n",
      " SVM Classifier Accuracy:\n",
      "0.3270982433311646\n",
      "None\n",
      " XGB Classifier Accuracy:\n",
      "0.29277813923227064\n",
      "None\n",
      " SGD Classifier Accuracy:\n",
      "0.3321405335068315\n",
      "None\n",
      " RF Classifier Accuracy:\n",
      "0.3767078724788549\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_ros, y_ros,X_test_data,test_y))\n",
    "print(LG_Classifier_result(X_ros, y_ros,X_test_data,test_y))\n",
    "print(SVM_Classifier_result(X_ros, y_ros,X_test_data,test_y))\n",
    "print(XG_Classifier_result(X_ros, y_ros,X_test_data,test_y))\n",
    "print(SGD_Classifier_result(X_ros, y_ros,X_test_data,test_y))\n",
    "print(RF_Classifier_result(X_ros, y_ros,X_test_data,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# passing Random under sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.50      0.58       327\n",
      "           2       0.35      0.29      0.32       370\n",
      "           3       0.37      0.29      0.32       468\n",
      "           4       0.30      0.51      0.38       614\n",
      "           5       0.75      0.66      0.70      1505\n",
      "\n",
      "    accuracy                           0.52      3284\n",
      "   macro avg       0.49      0.45      0.46      3284\n",
      "weighted avg       0.56      0.52      0.53      3284\n",
      "\n",
      "0.5225334957369062\n",
      "(0.5225334957369062, '              precision    recall  f1-score   support\\n\\n           1       0.68      0.50      0.58       327\\n           2       0.35      0.29      0.32       370\\n           3       0.37      0.29      0.32       468\\n           4       0.30      0.51      0.38       614\\n           5       0.75      0.66      0.70      1505\\n\\n    accuracy                           0.52      3284\\n   macro avg       0.49      0.45      0.46      3284\\nweighted avg       0.56      0.52      0.53      3284\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LG Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.51      0.56       293\n",
      "           2       0.36      0.30      0.33       371\n",
      "           3       0.39      0.27      0.32       538\n",
      "           4       0.43      0.51      0.47       868\n",
      "           5       0.66      0.72      0.69      1214\n",
      "\n",
      "    accuracy                           0.53      3284\n",
      "   macro avg       0.49      0.46      0.47      3284\n",
      "weighted avg       0.52      0.53      0.52      3284\n",
      "\n",
      "0.52557856272838\n",
      "(0.52557856272838, '              precision    recall  f1-score   support\\n\\n           1       0.62      0.51      0.56       293\\n           2       0.36      0.30      0.33       371\\n           3       0.39      0.27      0.32       538\\n           4       0.43      0.51      0.47       868\\n           5       0.66      0.72      0.69      1214\\n\\n    accuracy                           0.53      3284\\n   macro avg       0.49      0.46      0.47      3284\\nweighted avg       0.52      0.53      0.52      3284\\n')\n",
      " SVM Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.46      0.51       298\n",
      "           2       0.32      0.27      0.30       371\n",
      "           3       0.37      0.25      0.30       554\n",
      "           4       0.40      0.47      0.43       879\n",
      "           5       0.61      0.68      0.64      1182\n",
      "\n",
      "    accuracy                           0.49      3284\n",
      "   macro avg       0.46      0.43      0.44      3284\n",
      "weighted avg       0.48      0.49      0.48      3284\n",
      "\n",
      "0.48629719853836784\n",
      "(0.48629719853836784, '              precision    recall  f1-score   support\\n\\n           1       0.57      0.46      0.51       298\\n           2       0.32      0.27      0.30       371\\n           3       0.37      0.25      0.30       554\\n           4       0.40      0.47      0.43       879\\n           5       0.61      0.68      0.64      1182\\n\\n    accuracy                           0.49      3284\\n   macro avg       0.46      0.43      0.44      3284\\nweighted avg       0.48      0.49      0.48      3284\\n')\n",
      " XGB Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.48      0.56       335\n",
      "           2       0.41      0.34      0.37       383\n",
      "           3       0.39      0.27      0.32       528\n",
      "           4       0.38      0.51      0.44       787\n",
      "           5       0.68      0.72      0.70      1251\n",
      "\n",
      "    accuracy                           0.53      3284\n",
      "   macro avg       0.51      0.46      0.48      3284\n",
      "weighted avg       0.53      0.53      0.52      3284\n",
      "\n",
      "0.5274056029232643\n",
      "(0.5274056029232643, '              precision    recall  f1-score   support\\n\\n           1       0.68      0.48      0.56       335\\n           2       0.41      0.34      0.37       383\\n           3       0.39      0.27      0.32       528\\n           4       0.38      0.51      0.44       787\\n           5       0.68      0.72      0.70      1251\\n\\n    accuracy                           0.53      3284\\n   macro avg       0.51      0.46      0.48      3284\\nweighted avg       0.53      0.53      0.52      3284\\n')\n",
      " SGD Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.51      0.53       258\n",
      "           2       0.33      0.27      0.30       386\n",
      "           3       0.40      0.23      0.29       629\n",
      "           4       0.40      0.46      0.43       905\n",
      "           5       0.59      0.71      0.65      1106\n",
      "\n",
      "    accuracy                           0.48      3284\n",
      "   macro avg       0.45      0.44      0.44      3284\n",
      "weighted avg       0.47      0.48      0.47      3284\n",
      "\n",
      "0.4826431181485993\n",
      "(0.4826431181485993, '              precision    recall  f1-score   support\\n\\n           1       0.55      0.51      0.53       258\\n           2       0.33      0.27      0.30       386\\n           3       0.40      0.23      0.29       629\\n           4       0.40      0.46      0.43       905\\n           5       0.59      0.71      0.65      1106\\n\\n    accuracy                           0.48      3284\\n   macro avg       0.45      0.44      0.44      3284\\nweighted avg       0.47      0.48      0.47      3284\\n')\n",
      " RF Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.41      0.54       465\n",
      "           2       0.23      0.29      0.25       247\n",
      "           3       0.35      0.28      0.32       453\n",
      "           4       0.30      0.55      0.39       566\n",
      "           5       0.78      0.66      0.72      1553\n",
      "\n",
      "    accuracy                           0.53      3284\n",
      "   macro avg       0.49      0.44      0.44      3284\n",
      "weighted avg       0.60      0.53      0.55      3284\n",
      "\n",
      "0.5289281364190013\n",
      "(0.5289281364190013, '              precision    recall  f1-score   support\\n\\n           1       0.80      0.41      0.54       465\\n           2       0.23      0.29      0.25       247\\n           3       0.35      0.28      0.32       453\\n           4       0.30      0.55      0.39       566\\n           5       0.78      0.66      0.72      1553\\n\\n    accuracy                           0.53      3284\\n   macro avg       0.49      0.44      0.44      3284\\nweighted avg       0.60      0.53      0.55      3284\\n')\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_rus, y_rus,X_test_dtm,y_test))\n",
    "print(LG_Classifier_result(X_rus, y_rus,X_test_dtm,y_test))\n",
    "print(SVM_Classifier_result(X_rus, y_rus,X_test_dtm,y_test))\n",
    "print(XG_Classifier_result(X_rus, y_rus,X_test_dtm,y_test))\n",
    "print(SGD_Classifier_result(X_rus, y_rus,X_test_dtm,y_test))\n",
    "print(RF_Classifier_result(X_rus, y_rus,X_test_dtm,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression : 0.52557856272838\n",
    "\n",
    "(Multinomial) Naive Bayes :0.5225334957369062\n",
    "\n",
    "Linear Support Vector Machine : 0.48629719853836784\n",
    "\n",
    "Xgboost : 0.5274056029232643\n",
    "\n",
    "SGD classifier : 0.4826431181485993\n",
    "\n",
    "Random Forest :  0.5289281364190013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Classifier test data Accuracy:\n",
      "0.24105400130123616\n",
      "None\n",
      " LG Classifier Accuracy:\n",
      "0.2797657774886142\n",
      "None\n",
      " SVM Classifier Accuracy:\n",
      "0.27683799609629145\n",
      "None\n",
      " XGB Classifier Accuracy:\n",
      "0.2691932335718933\n",
      "None\n",
      " SGD Classifier Accuracy:\n",
      "0.27765126870527\n",
      "None\n",
      " RF Classifier Accuracy:\n",
      "0.28871177618737803\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_rus, y_rus,X_test_data,test_y))\n",
    "print(LG_Classifier_result(X_rus, y_rus,X_test_data,test_y))\n",
    "print(SVM_Classifier_result(X_rus, y_rus,X_test_data,test_y))\n",
    "print(XG_Classifier_result(X_rus, y_rus,X_test_data,test_y))\n",
    "print(SGD_Classifier_result(X_rus, y_rus,X_test_data,test_y))\n",
    "print(RF_Classifier_result(X_rus, y_rus,X_test_data,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TomekLinks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.52      0.57       291\n",
      "           2       0.34      0.33      0.34       330\n",
      "           3       0.28      0.36      0.31       285\n",
      "           4       0.38      0.54      0.44       720\n",
      "           5       0.81      0.65      0.72      1658\n",
      "\n",
      "    accuracy                           0.56      3284\n",
      "   macro avg       0.49      0.48      0.48      3284\n",
      "weighted avg       0.61      0.56      0.57      3284\n",
      "\n",
      "0.557551766138855\n",
      "(0.557551766138855, '              precision    recall  f1-score   support\\n\\n           1       0.64      0.52      0.57       291\\n           2       0.34      0.33      0.34       330\\n           3       0.28      0.36      0.31       285\\n           4       0.38      0.54      0.44       720\\n           5       0.81      0.65      0.72      1658\\n\\n    accuracy                           0.56      3284\\n   macro avg       0.49      0.48      0.48      3284\\nweighted avg       0.61      0.56      0.57      3284\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LG Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.57      0.56       229\n",
      "           2       0.31      0.35      0.32       278\n",
      "           3       0.31      0.32      0.32       354\n",
      "           4       0.50      0.51      0.50      1020\n",
      "           5       0.73      0.69      0.71      1403\n",
      "\n",
      "    accuracy                           0.56      3284\n",
      "   macro avg       0.48      0.49      0.48      3284\n",
      "weighted avg       0.56      0.56      0.56      3284\n",
      "\n",
      "0.5554202192448234\n",
      "(0.5554202192448234, '              precision    recall  f1-score   support\\n\\n           1       0.54      0.57      0.56       229\\n           2       0.31      0.35      0.32       278\\n           3       0.31      0.32      0.32       354\\n           4       0.50      0.51      0.50      1020\\n           5       0.73      0.69      0.71      1403\\n\\n    accuracy                           0.56      3284\\n   macro avg       0.48      0.49      0.48      3284\\nweighted avg       0.56      0.56      0.56      3284\\n')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sathi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SVM Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.49      0.46       207\n",
      "           2       0.26      0.30      0.28       275\n",
      "           3       0.28      0.27      0.27       371\n",
      "           4       0.46      0.45      0.46      1047\n",
      "           5       0.68      0.66      0.67      1384\n",
      "\n",
      "    accuracy                           0.51      3284\n",
      "   macro avg       0.42      0.44      0.43      3284\n",
      "weighted avg       0.51      0.51      0.51      3284\n",
      "\n",
      "0.5079171741778319\n",
      "(0.5079171741778319, '              precision    recall  f1-score   support\\n\\n           1       0.43      0.49      0.46       207\\n           2       0.26      0.30      0.28       275\\n           3       0.28      0.27      0.27       371\\n           4       0.46      0.45      0.46      1047\\n           5       0.68      0.66      0.67      1384\\n\\n    accuracy                           0.51      3284\\n   macro avg       0.42      0.44      0.43      3284\\nweighted avg       0.51      0.51      0.51      3284\\n')\n",
      " XGB Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.64      0.58       200\n",
      "           2       0.29      0.43      0.35       213\n",
      "           3       0.16      0.36      0.22       159\n",
      "           4       0.54      0.52      0.53      1081\n",
      "           5       0.81      0.66      0.73      1631\n",
      "\n",
      "    accuracy                           0.59      3284\n",
      "   macro avg       0.47      0.52      0.48      3284\n",
      "weighted avg       0.64      0.59      0.61      3284\n",
      "\n",
      "0.5852618757612668\n",
      "(0.5852618757612668, '              precision    recall  f1-score   support\\n\\n           1       0.53      0.64      0.58       200\\n           2       0.29      0.43      0.35       213\\n           3       0.16      0.36      0.22       159\\n           4       0.54      0.52      0.53      1081\\n           5       0.81      0.66      0.73      1631\\n\\n    accuracy                           0.59      3284\\n   macro avg       0.47      0.52      0.48      3284\\nweighted avg       0.64      0.59      0.61      3284\\n')\n",
      " SGD Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.49      0.56      0.53       209\n",
      "           2       0.24      0.32      0.28       237\n",
      "           3       0.27      0.28      0.27       359\n",
      "           4       0.47      0.49      0.48       993\n",
      "           5       0.72      0.64      0.68      1486\n",
      "\n",
      "    accuracy                           0.53      3284\n",
      "   macro avg       0.44      0.46      0.45      3284\n",
      "weighted avg       0.54      0.53      0.53      3284\n",
      "\n",
      "0.5261875761266748\n",
      "(0.5261875761266748, '              precision    recall  f1-score   support\\n\\n           1       0.49      0.56      0.53       209\\n           2       0.24      0.32      0.28       237\\n           3       0.27      0.28      0.27       359\\n           4       0.47      0.49      0.48       993\\n           5       0.72      0.64      0.68      1486\\n\\n    accuracy                           0.53      3284\\n   macro avg       0.44      0.46      0.45      3284\\nweighted avg       0.54      0.53      0.53      3284\\n')\n",
      " RF Classifier result:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.67      0.55       166\n",
      "           2       0.04      0.48      0.08        29\n",
      "           3       0.00      0.17      0.01         6\n",
      "           4       0.53      0.46      0.49      1198\n",
      "           5       0.88      0.62      0.73      1885\n",
      "\n",
      "    accuracy                           0.56      3284\n",
      "   macro avg       0.38      0.48      0.37      3284\n",
      "weighted avg       0.72      0.56      0.62      3284\n",
      "\n",
      "0.5596833130328868\n",
      "(0.5596833130328868, '              precision    recall  f1-score   support\\n\\n           1       0.46      0.67      0.55       166\\n           2       0.04      0.48      0.08        29\\n           3       0.00      0.17      0.01         6\\n           4       0.53      0.46      0.49      1198\\n           5       0.88      0.62      0.73      1885\\n\\n    accuracy                           0.56      3284\\n   macro avg       0.38      0.48      0.37      3284\\nweighted avg       0.72      0.56      0.62      3284\\n')\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_tl,y_tl,X_test_dtm,y_test))\n",
    "print(LG_Classifier_result(X_tl,y_tl,X_test_dtm,y_test))\n",
    "print(SVM_Classifier_result(X_tl,y_tl,X_test_dtm,y_test))\n",
    "print(XG_Classifier_result(X_tl,y_tl,X_test_dtm,y_test))\n",
    "print(SGD_Classifier_result(X_tl,y_tl,X_test_dtm,y_test))\n",
    "print(RF_Classifier_result(X_tl,y_tl,X_test_dtm,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression : 0.5554202192448234\n",
    "\n",
    "(Multinomial) Naive Bayes :0.557551766138855\n",
    "\n",
    "Linear Support Vector Machine : 0.5079171741778319\n",
    "\n",
    "Xgboost : 0.5852618757612668\n",
    "\n",
    "SGD classifier : 0.5261875761266748\n",
    "\n",
    "Random Forest : 0.5596833130328868"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Classifier test data Accuracy:\n",
      "0.4201366297983084\n",
      "None\n",
      " LG Classifier Accuracy:\n",
      "0.3282368249837345\n",
      "None\n",
      " SVM Classifier Accuracy:\n",
      "0.3280741704619388\n",
      "None\n",
      " XGB Classifier Accuracy:\n",
      "0.346779440468445\n",
      "None\n",
      " SGD Classifier Accuracy:\n",
      "0.32286922576447624\n",
      "None\n",
      " RF Classifier Accuracy:\n",
      "0.435263500325309\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_tl,y_tl,X_test_data,test_y))\n",
    "\n",
    "print(LG_Classifier_result(X_tl,y_tl,X_test_data,test_y))\n",
    "print(SVM_Classifier_result(X_tl,y_tl,X_test_data,test_y))\n",
    "print(XG_Classifier_result(X_tl,y_tl,X_test_data,test_y))\n",
    "print(SGD_Classifier_result(X_tl,y_tl,X_test_data,test_y))\n",
    "print(RF_Classifier_result(X_tl,y_tl,X_test_data,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTETomek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.13      0.94      0.23        34\n",
      "         2.0       0.04      0.24      0.07        50\n",
      "         3.0       0.01      0.60      0.02         5\n",
      "         4.0       0.25      0.31      0.28       840\n",
      "         5.0       0.93      0.57      0.71      2657\n",
      "\n",
      "    accuracy                           0.51      3586\n",
      "   macro avg       0.27      0.53      0.26      3586\n",
      "weighted avg       0.75      0.51      0.59      3586\n",
      "\n",
      "0.5080870050195203\n",
      "NB Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.58      0.58      0.58       243\n",
      "         2.0       0.35      0.35      0.35       318\n",
      "         3.0       0.36      0.30      0.33       453\n",
      "         4.0       0.42      0.44      0.43       986\n",
      "         5.0       0.69      0.71      0.70      1586\n",
      "\n",
      "    accuracy                           0.54      3586\n",
      "   macro avg       0.48      0.48      0.48      3586\n",
      "weighted avg       0.54      0.54      0.54      3586\n",
      "\n",
      "0.5421081985499163\n",
      " LG Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.52      0.53      0.52       237\n",
      "         2.0       0.30      0.26      0.28       374\n",
      "         3.0       0.36      0.24      0.29       577\n",
      "         4.0       0.38      0.39      0.38       979\n",
      "         5.0       0.56      0.64      0.60      1419\n",
      "\n",
      "    accuracy                           0.46      3586\n",
      "   macro avg       0.42      0.41      0.41      3586\n",
      "weighted avg       0.45      0.46      0.45      3586\n",
      "\n",
      "0.46235359732292247\n",
      " SVM Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.56      0.62      0.59       219\n",
      "         2.0       0.23      0.41      0.29       175\n",
      "         3.0       0.13      0.38      0.19       131\n",
      "         4.0       0.46      0.43      0.44      1078\n",
      "         5.0       0.82      0.67      0.73      1983\n",
      "\n",
      "    accuracy                           0.57      3586\n",
      "   macro avg       0.44      0.50      0.45      3586\n",
      "weighted avg       0.64      0.57      0.60      3586\n",
      "\n",
      "0.5702732849972114\n",
      " XGB Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.55      0.49      0.52       271\n",
      "         2.0       0.34      0.28      0.31       381\n",
      "         3.0       0.29      0.29      0.29       392\n",
      "         4.0       0.36      0.42      0.39       886\n",
      "         5.0       0.70      0.69      0.70      1656\n",
      "\n",
      "    accuracy                           0.52      3586\n",
      "   macro avg       0.45      0.43      0.44      3586\n",
      "weighted avg       0.52      0.52      0.52      3586\n",
      "\n",
      "0.5192414947016174\n",
      " SGD Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.42      0.57      0.48       176\n",
      "         2.0       0.09      0.41      0.15        74\n",
      "         3.0       0.10      0.25      0.14       154\n",
      "         4.0       0.12      0.42      0.18       288\n",
      "         5.0       0.92      0.52      0.66      2894\n",
      "\n",
      "    accuracy                           0.50      3586\n",
      "   macro avg       0.33      0.43      0.33      3586\n",
      "weighted avg       0.78      0.50      0.58      3586\n",
      "\n",
      "0.4986056887897379\n",
      " RF Classifier result:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_smt,y_smt,X_test_dtm,y_test))\n",
    "print(LG_Classifier_result(X_smt,y_smt,X_test_dtm,y_test))\n",
    "print(SVM_Classifier_result(X_smt,y_smt,X_test_dtm,y_test))\n",
    "print(XG_Classifier_result(X_smt,y_smt,X_test_dtm,y_test))\n",
    "print(SGD_Classifier_result(X_smt,y_smt,X_test_dtm,y_test))\n",
    "print(RF_Classifier_result(X_smt,y_smt,X_test_dtm,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression : 0.5421081985499163\n",
    "\n",
    "(Multinomial) Naive Bayes : 0.5080870050195203\n",
    "\n",
    "Linear Support Vector Machine : 0.46235359732292247\n",
    "\n",
    "Xgboost : 0.5702732849972114\n",
    "\n",
    "SGD classifier : 0.5192414947016174\n",
    "\n",
    "Random Forest : 0.4986056887897379"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Classifier test data Accuracy:\n",
      "0.4035458685751464\n",
      "None\n",
      " LG Classifier Accuracy:\n",
      "0.2979830839297333\n",
      "None\n",
      " SVM Classifier Accuracy:\n",
      "0.280416395575797\n",
      "None\n",
      " XGB Classifier Accuracy:\n",
      "0.34726740403383216\n",
      "None\n",
      " SGD Classifier Accuracy:\n",
      "0.2916395575797007\n",
      "None\n",
      " RF Classifier Accuracy:\n",
      "0.39769030579050096\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_smt,y_smt,X_test_data,test_y))\n",
    "\n",
    "print(LG_Classifier_result(X_smt,y_smt,X_test_data,test_y))\n",
    "print(SVM_Classifier_result(X_smt,y_smt,X_test_data,test_y))\n",
    "print(XG_Classifier_result(X_smt,y_smt,X_test_data,test_y))\n",
    "print(SGD_Classifier_result(X_smt,y_smt,X_test_data,test_y))\n",
    "print(RF_Classifier_result(X_smt,y_smt,X_test_data,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=pd.read_pickle(\"stp_wrds.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=word_tokenize,stop_words=stop, lowercase=False, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforming test data and train data in to a document term matrix\n",
    "X_Train_Dtm=vectorizer.fit_transform(X_train)\n",
    "X_Test_Dtm=vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10757, 549336), (10757,), (3586, 549336), (3586,))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train_Dtm.shape, y_train.shape,X_Test_Dtm.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model : Passing imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "         2.0       0.00      0.00      0.00         0\n",
      "         3.0       0.00      0.00      0.00         0\n",
      "         4.0       0.00      0.00      0.00         0\n",
      "         5.0       1.00      0.45      0.62      3586\n",
      "\n",
      "    accuracy                           0.45      3586\n",
      "   macro avg       0.20      0.09      0.12      3586\n",
      "weighted avg       1.00      0.45      0.62      3586\n",
      "\n",
      "0.4520356943669827\n",
      "NB Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.40      0.75      0.52       130\n",
      "         2.0       0.16      0.37      0.22       139\n",
      "         3.0       0.04      0.30      0.07        53\n",
      "         4.0       0.47      0.43      0.45      1130\n",
      "         5.0       0.86      0.65      0.74      2134\n",
      "\n",
      "    accuracy                           0.57      3586\n",
      "   macro avg       0.39      0.50      0.40      3586\n",
      "weighted avg       0.68      0.57      0.61      3586\n",
      "\n",
      "0.5694366982710541\n",
      " LG Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.61      0.62      0.61       235\n",
      "         2.0       0.25      0.45      0.32       177\n",
      "         3.0       0.17      0.43      0.25       156\n",
      "         4.0       0.48      0.46      0.47      1055\n",
      "         5.0       0.83      0.68      0.75      1963\n",
      "\n",
      "    accuracy                           0.59      3586\n",
      "   macro avg       0.47      0.53      0.48      3586\n",
      "weighted avg       0.65      0.59      0.62      3586\n",
      "\n",
      "0.5923034021193531\n",
      " SVM Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.56      0.62      0.59       216\n",
      "         2.0       0.25      0.44      0.32       179\n",
      "         3.0       0.21      0.36      0.27       233\n",
      "         4.0       0.48      0.44      0.46      1110\n",
      "         5.0       0.79      0.69      0.73      1848\n",
      "\n",
      "    accuracy                           0.57      3586\n",
      "   macro avg       0.46      0.51      0.47      3586\n",
      "weighted avg       0.61      0.57      0.59      3586\n",
      "\n",
      "0.5738984941438929\n",
      " XGB Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.71      0.59      0.65       289\n",
      "         2.0       0.17      0.46      0.25       119\n",
      "         3.0       0.12      0.40      0.18       114\n",
      "         4.0       0.42      0.46      0.44       941\n",
      "         5.0       0.87      0.67      0.75      2123\n",
      "\n",
      "    accuracy                           0.59      3586\n",
      "   macro avg       0.46      0.52      0.46      3586\n",
      "weighted avg       0.69      0.59      0.63      3586\n",
      "\n",
      "0.5900725041829337\n",
      " SGD Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.07      0.95      0.14        19\n",
      "         2.0       0.01      0.50      0.01         4\n",
      "         3.0       0.00      0.00      0.00         0\n",
      "         4.0       0.10      0.33      0.15       295\n",
      "         5.0       0.97      0.48      0.65      3268\n",
      "\n",
      "    accuracy                           0.47      3586\n",
      "   macro avg       0.23      0.45      0.19      3586\n",
      "weighted avg       0.90      0.47      0.60      3586\n",
      "\n",
      "0.47267150027886223\n",
      " RF Classifier result:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_Train_Dtm, y_train,X_Test_Dtm,y_test))\n",
    "print(LG_Classifier_result(X_Train_Dtm, y_train,X_Test_Dtm,y_test)) \n",
    "print(SVM_Classifier_result(X_Train_Dtm, y_train,X_Test_Dtm,y_test))\n",
    "print(XG_Classifier_result(X_Train_Dtm, y_train,X_Test_Dtm,y_test))\n",
    "print(SGD_Classifier_result(X_Train_Dtm, y_train,X_Test_Dtm,y_test))\n",
    "print(RF_Classifier_result(X_Train_Dtm, y_train,X_Test_Dtm,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passing Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Classifier test data Accuracy:\n",
      "0.4500650618087183\n",
      "None\n",
      " LG Classifier Accuracy:\n",
      "0.30383864671437866\n",
      "None\n",
      " SVM Classifier Accuracy:\n",
      "0.314736499674691\n",
      "None\n",
      " XGB Classifier Accuracy:\n",
      "0.29212752114508783\n",
      "None\n",
      " SGD Classifier Accuracy:\n",
      "0.31733897202342226\n",
      "None\n",
      " RF Classifier Accuracy:\n",
      "0.40777488614183477\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_Train_Dtm, y_train,X_test_data,test_y))\n",
    "\n",
    "print(LG_Classifier_result(X_Train_Dtm, y_train,X_test_data,test_y))\n",
    "print(SVM_Classifier_result(X_Train_Dtm, y_train,X_test_data,test_y))\n",
    "print(XG_Classifier_result(X_Train_Dtm, y_train,X_test_data,test_y))\n",
    "print(SGD_Classifier_result(X_Train_Dtm, y_train,X_test_data,test_y))\n",
    "print(RF_Classifier_result(X_Train_Dtm, y_train,X_test_data,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model : Passing balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14836, 549336) (14836,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE('minority')\n",
    "\n",
    "X_sm_t, y_sm_t = smote.fit_sample(X_Train_Dtm, y_train)\n",
    "print(X_sm_t.shape, y_sm_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "X_ros_t, y_ros_t = ros.fit_sample(X_Train_Dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10353, 549336), (10353,))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "tl = TomekLinks('majority')\n",
    "X_tl_t, y_tl_t = tl.fit_sample(X_Train_Dtm, y_train)\n",
    "X_tl_t.shape,y_tl_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek('auto')\n",
    "X_smt_t, y_smt_t = smt.fit_sample(X_Train_Dtm, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passing SMOTE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.99      0.29      0.45       816\n",
      "         2.0       0.00      0.00      0.00         0\n",
      "         3.0       0.00      0.00      0.00         0\n",
      "         4.0       0.00      0.00      0.00         0\n",
      "         5.0       0.96      0.56      0.71      2770\n",
      "\n",
      "    accuracy                           0.50      3586\n",
      "   macro avg       0.39      0.17      0.23      3586\n",
      "weighted avg       0.97      0.50      0.65      3586\n",
      "\n",
      "0.501952035694367\n",
      "NB Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.85      0.48      0.61       427\n",
      "         2.0       0.00      0.00      0.00         0\n",
      "         3.0       0.01      0.33      0.01         6\n",
      "         4.0       0.48      0.43      0.45      1128\n",
      "         5.0       0.84      0.68      0.75      2025\n",
      "\n",
      "    accuracy                           0.57      3586\n",
      "   macro avg       0.44      0.38      0.37      3586\n",
      "weighted avg       0.73      0.57      0.64      3586\n",
      "\n",
      "0.5747350808700502\n",
      " LG Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.76      0.57      0.65       320\n",
      "         2.0       0.14      0.49      0.22        89\n",
      "         3.0       0.07      0.34      0.12        85\n",
      "         4.0       0.53      0.45      0.49      1198\n",
      "         5.0       0.83      0.71      0.76      1894\n",
      "\n",
      "    accuracy                           0.60      3586\n",
      "   macro avg       0.47      0.51      0.45      3586\n",
      "weighted avg       0.69      0.60      0.63      3586\n",
      "\n",
      "0.596207473508087\n",
      " SVM Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.32      0.64      0.42       118\n",
      "         2.0       0.32      0.38      0.35       266\n",
      "         3.0       0.30      0.27      0.28       443\n",
      "         4.0       0.49      0.43      0.46      1163\n",
      "         5.0       0.70      0.71      0.71      1596\n",
      "\n",
      "    accuracy                           0.54      3586\n",
      "   macro avg       0.43      0.49      0.44      3586\n",
      "weighted avg       0.54      0.54      0.54      3586\n",
      "\n",
      "0.5393195761293921\n",
      " XGB Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.85      0.48      0.62       424\n",
      "         2.0       0.03      0.43      0.06        23\n",
      "         3.0       0.04      0.35      0.08        48\n",
      "         4.0       0.36      0.42      0.39       864\n",
      "         5.0       0.89      0.65      0.75      2227\n",
      "\n",
      "    accuracy                           0.57      3586\n",
      "   macro avg       0.44      0.47      0.38      3586\n",
      "weighted avg       0.74      0.57      0.63      3586\n",
      "\n",
      "0.5697155605131066\n",
      " SGD Classifier result:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_sm_t, y_sm_t,X_Test_Dtm,y_test))\n",
    "print(LG_Classifier_result(X_sm_t, y_sm_t,X_Test_Dtm,y_test))\n",
    "print(SVM_Classifier_result(X_sm_t, y_sm_t,X_Test_Dtm,y_test))\n",
    "print(XG_Classifier_result(X_sm_t, y_sm_t,X_Test_Dtm,y_test))\n",
    "print(SGD_Classifier_result(X_sm_t, y_sm_t,X_Test_Dtm,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.44      0.57      0.49       185\n",
      "         2.0       0.00      0.00      0.00         0\n",
      "         3.0       0.00      0.00      0.00         0\n",
      "         4.0       0.03      0.34      0.06        91\n",
      "         5.0       0.99      0.48      0.65      3310\n",
      "\n",
      "    accuracy                           0.49      3586\n",
      "   macro avg       0.29      0.28      0.24      3586\n",
      "weighted avg       0.94      0.49      0.63      3586\n",
      "\n",
      "0.4854991634132738\n",
      " RF Classifier result:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(RF_Classifier_result(X_sm_t, y_sm_t,X_Test_Dtm,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Classifier test data Accuracy:\n",
      "0.37800910865322057\n",
      "None\n",
      " LG Classifier Accuracy:\n",
      "0.30123617436564737\n",
      "None\n",
      " SVM Classifier Accuracy:\n",
      "0.31441119063109957\n",
      "None\n",
      " XGB Classifier Accuracy:\n",
      "0.3015614834092388\n",
      "None\n",
      " SGD Classifier Accuracy:\n",
      "0.32270657124268054\n",
      "None\n",
      " RF Classifier Accuracy:\n",
      "0.41379310344827586\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_sm_t, y_sm_t,X_test_data,test_y))\n",
    "\n",
    "print(LG_Classifier_result(X_sm_t, y_sm_t,X_test_data,test_y))\n",
    "print(SVM_Classifier_result(X_sm_t, y_sm_t,X_test_data,test_y))\n",
    "print(XG_Classifier_result(X_sm_t, y_sm_t,X_test_data,test_y))\n",
    "print(SGD_Classifier_result(X_sm_t, y_sm_t,X_test_data,test_y))\n",
    "print(RF_Classifier_result(X_sm_t, y_sm_t,X_test_data,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# passing SMOTETOMEK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.52      0.62      0.57       202\n",
      "         2.0       0.52      0.29      0.37       578\n",
      "         3.0       0.35      0.28      0.31       478\n",
      "         4.0       0.56      0.45      0.50      1277\n",
      "         5.0       0.53      0.82      0.64      1051\n",
      "\n",
      "    accuracy                           0.52      3586\n",
      "   macro avg       0.50      0.49      0.48      3586\n",
      "weighted avg       0.52      0.52      0.50      3586\n",
      "\n",
      "0.5186837702175126\n",
      "NB Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.60      0.61      0.60       237\n",
      "         2.0       0.35      0.39      0.37       285\n",
      "         3.0       0.30      0.40      0.34       287\n",
      "         4.0       0.55      0.50      0.53      1132\n",
      "         5.0       0.76      0.75      0.75      1645\n",
      "\n",
      "    accuracy                           0.60      3586\n",
      "   macro avg       0.51      0.53      0.52      3586\n",
      "weighted avg       0.61      0.60      0.61      3586\n",
      "\n",
      "0.60345789180145\n",
      " LG Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.61      0.60      0.61       248\n",
      "         2.0       0.26      0.40      0.31       210\n",
      "         3.0       0.22      0.39      0.29       222\n",
      "         4.0       0.49      0.47      0.48      1066\n",
      "         5.0       0.80      0.71      0.75      1840\n",
      "\n",
      "    accuracy                           0.59      3586\n",
      "   macro avg       0.48      0.51      0.49      3586\n",
      "weighted avg       0.63      0.59      0.61      3586\n",
      "\n",
      "0.5900725041829337\n",
      " SVM Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.58      0.57      0.57       247\n",
      "         2.0       0.18      0.35      0.24       165\n",
      "         3.0       0.23      0.41      0.29       218\n",
      "         4.0       0.45      0.45      0.45      1017\n",
      "         5.0       0.79      0.66      0.72      1939\n",
      "\n",
      "    accuracy                           0.56      3586\n",
      "   macro avg       0.45      0.49      0.45      3586\n",
      "weighted avg       0.62      0.56      0.58      3586\n",
      "\n",
      "0.5638594534300055\n",
      " XGB Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.65      0.56      0.60       282\n",
      "         2.0       0.31      0.37      0.34       265\n",
      "         3.0       0.30      0.39      0.34       300\n",
      "         4.0       0.46      0.51      0.48       906\n",
      "         5.0       0.81      0.72      0.76      1833\n",
      "\n",
      "    accuracy                           0.60      3586\n",
      "   macro avg       0.51      0.51      0.51      3586\n",
      "weighted avg       0.63      0.60      0.61      3586\n",
      "\n",
      "0.6023424428332403\n",
      " SGD Classifier result:\n",
      "None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.39      0.67      0.49       138\n",
      "         2.0       0.03      0.29      0.06        35\n",
      "         3.0       0.02      0.46      0.03        13\n",
      "         4.0       0.25      0.37      0.30       689\n",
      "         5.0       0.89      0.53      0.67      2711\n",
      "\n",
      "    accuracy                           0.50      3586\n",
      "   macro avg       0.31      0.46      0.31      3586\n",
      "weighted avg       0.74      0.50      0.58      3586\n",
      "\n",
      "0.5033463469046291\n",
      " RF Classifier result:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_smt_t, y_smt_t,X_Test_Dtm,y_test))\n",
    "print(LG_Classifier_result(X_smt_t, y_smt_t,X_Test_Dtm,y_test))\n",
    "print(SVM_Classifier_result(X_smt_t, y_smt_t,X_Test_Dtm,y_test))\n",
    "print(XG_Classifier_result(X_smt_t, y_smt_t,X_Test_Dtm,y_test))\n",
    "print(SGD_Classifier_result(X_smt_t, y_smt_t,X_Test_Dtm,y_test))\n",
    "print(RF_Classifier_result(X_smt_t, y_smt_t,X_Test_Dtm,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# passing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Classifier test data Accuracy:\n",
      "0.25731945348080676\n",
      "None\n",
      " LG Classifier Accuracy:\n",
      "0.2770006506180872\n",
      "None\n",
      " SVM Classifier Accuracy:\n",
      "0.30611581001951854\n",
      "None\n",
      " XGB Classifier Accuracy:\n",
      "0.36759921925829536\n",
      "None\n",
      " SGD Classifier Accuracy:\n",
      "0.2968445022771633\n",
      "None\n",
      " RF Classifier Accuracy:\n",
      "0.40013012361743655\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(NB_Classifier_result(X_smt_t, y_smt_t,X_test_data,test_y))\n",
    "\n",
    "print(LG_Classifier_result(X_smt_t, y_smt_t,X_test_data,test_y))\n",
    "print(SVM_Classifier_result(X_smt_t, y_smt_t,X_test_data,test_y))\n",
    "print(XG_Classifier_result(X_smt_t, y_smt_t,X_test_data,test_y))\n",
    "print(SGD_Classifier_result(X_smt_t, y_smt_t,X_test_data,test_y))\n",
    "print(RF_Classifier_result(X_smt_t, y_smt_t,X_test_data,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take SGD classifier as best model(TF-IDF-SMOTETOMEK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(tol=0.01)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD = SGDClassifier(max_iter=1000, tol=0.01)\n",
    "SGD.fit(X_smt_t, y_smt_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 5., 5., ..., 5., 5., 5.])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=SGD.predict(X_Test_Dtm)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6017847183491355"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model to disk\n",
    "import pickle\n",
    "pickle.dump(SGD, open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create pickle file TF_IDF vecorizer\n",
    "pickle.dump(vectorizer, open('tranform.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(class_weight={1: 0.4468120456905504, 2: 0.6825507614213198,\n",
       "                  3: 1.915761353517364, 4: 2.3108485499462943,\n",
       "                  5: 2.9230978260869565},\n",
       "    kernel='linear')"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVC include parameter class_weight\n",
    "from sklearn.svm import SVC\n",
    "model = SVC(C=10, gamma=1,kernel='linear',class_weight=weight) \n",
    "model.fit(X_sm_t, y_sm_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_Test_Dtm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5984383714445064"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': array([1.00000000e-05, 8.48342898e-05, 7.19685673e-04, 6.10540230e-03,\n",
       "       5.17947468e-02, 4.39397056e-01, 3.72759372e+00, 3.16227766e+01,\n",
       "       2.68269580e+02, 2.27584593e+03, 1.93069773e+04, 1.63789371e+05,\n",
       "       1.38949549e+06, 1.17876863e+07, 1.00000000e+08])})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOGISTIC REGRESSION\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "  \n",
    "# Creating the hyperparameter grid \n",
    "c_space = np.logspace(-5, 8, 15) \n",
    "param_grid = {'C': c_space} \n",
    "  \n",
    "# Instantiating logistic regression classifier \n",
    "logreg = LogisticRegression() \n",
    "  \n",
    "# Instantiating the GridSearchCV object \n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv = 5) \n",
    "  \n",
    "logreg_cv.fit(X_smt_t, y_smt_t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9140602284527517"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 268.2695795279727}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=268.2695795279727)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression(C=268.2695795279727)\n",
    "lr.fit(X_smt_t, y_smt_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 4., 5., ..., 5., 5., 5.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=lr.predict(X_Test_Dtm)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6045733407696597"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGD CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SGDClassifier(),\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
       "                         'loss': ['hinge', 'log', 'squared_hinge',\n",
       "                                  'modified_huber'],\n",
       "                         'penalty': ['l2', 'l1', 'none']})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"loss\" : [\"hinge\", \"log\", \"squared_hinge\", \"modified_huber\"],\n",
    "    \"alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"penalty\" : [\"l2\", \"l1\", \"none\"],\n",
    "}\n",
    "\n",
    "model = SGDClassifier(max_iter=1000)\n",
    "clf = GridSearchCV(model, param_grid=params)\n",
    "clf.fit(X_smt_t, y_smt_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(loss='squared_hinge')\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0001, 'loss': 'squared_hinge', 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_model = SGDClassifier(max_iter=1000,alpha= 0.0001, loss= 'squared_hinge', penalty= 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(loss='squared_hinge')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_model.fit(X_tl_t,y_tl_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 4., 5., ..., 5., 5., 5.])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=sg_model.predict(X_Test_Dtm)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5900725041829337"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       superb rendezvous perfect property singapore f...\n",
       "1       better close staten island ferry easy subway r...\n",
       "2       enjoyed stay come long weekend barcelona staye...\n",
       "3       muse great muse hotel great hear noise reviewe...\n",
       "4       conveniently located morning flight family sta...\n",
       "                              ...                        \n",
       "6143    great hotel pre cruise great hotel arrived ear...\n",
       "6144    great choice returned nights grand hotel franc...\n",
       "6145    overpriced tiny rooms kowloon past use date ne...\n",
       "6146    ok agree said positive staff helpful rooms cle...\n",
       "6147    great location husband stayed new orleans 6106...\n",
       "Name: Review, Length: 6148, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have already a test data..we can apply test_X data to check the accuaracy of a predicted model\n",
    "\n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6148x549336 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 644215 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_datas = vectorizer.transform(test_X)\n",
    "X_test_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 4. 4. ... 3. 4. 4.]\n"
     ]
    }
   ],
   "source": [
    "y_pred1=lr.predict(X_test_datas)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF - USING DIAMENSION REDUCTION -PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6143</th>\n",
       "      <td>6143</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6144</th>\n",
       "      <td>6144</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6145</th>\n",
       "      <td>6145</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6146</th>\n",
       "      <td>6146</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6147</th>\n",
       "      <td>6147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6148 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Rating\n",
       "0        0       5\n",
       "1        1       2\n",
       "2        2       4\n",
       "3        3       5\n",
       "4        4       4\n",
       "...    ...     ...\n",
       "6143  6143       5\n",
       "6144  6144       5\n",
       "6145  6145       3\n",
       "6146  6146       4\n",
       "6147  6147       3\n",
       "\n",
       "[6148 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upload sample submission file\n",
    "sample_df=pd.read_csv(\"sample submission (2).csv\")\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding predicted Item_Outlet_Sales in to sample_df\n",
    "pred=pd.DataFrame(y_pred)\n",
    "data=pd.concat([sample_df[\"ID\"],pred],axis=1)\n",
    "\n",
    "data.columns=[\"ID\",\"Rating\"]\n",
    "data.to_csv(\"sample submission (2).csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6143</th>\n",
       "      <td>6143</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6144</th>\n",
       "      <td>6144</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6145</th>\n",
       "      <td>6145</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6146</th>\n",
       "      <td>6146</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6147</th>\n",
       "      <td>6147</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6148 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Rating\n",
       "0        0       5\n",
       "1        1       3\n",
       "2        2       5\n",
       "3        3       5\n",
       "4        4       5\n",
       "...    ...     ...\n",
       "6143  6143       5\n",
       "6144  6144       5\n",
       "6145  6145       1\n",
       "6146  6146       5\n",
       "6147  6147       5\n",
       "\n",
       "[6148 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
